{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5224199b-6994-43c5-a296-f35e25679978",
   "metadata": {
    "id": "5224199b-6994-43c5-a296-f35e25679978"
   },
   "source": [
    "# Markov Chain Monte Carlo with Couplings, parallelized, multivariate mean Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0606a6-8bb5-4536-a398-b9c8213f61a8",
   "metadata": {
    "id": "8c0606a6-8bb5-4536-a398-b9c8213f61a8"
   },
   "source": [
    "## Modules importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc0c76c-1f63-458d-89cd-c0ecd1a7b2f1",
   "metadata": {
    "id": "7dc0c76c-1f63-458d-89cd-c0ecd1a7b2f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-13 18:40:37.791491: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-13 18:40:37.791519: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# system modules\n",
    "import os\n",
    "import time\n",
    "\n",
    "# mathematical and statistical modules\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sstat\n",
    "#from mpmath import mp\n",
    "\n",
    "# tensorflow modules\n",
    "import tensorflow_probability.substrates.numpy as tfp\n",
    "import tensorflow_probability.substrates.numpy.distributions as tfd\n",
    "import tensorflow.random as tfr\n",
    "\n",
    "# visualization and plotting modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# parallelization modules \n",
    "from multiprocessing import Process, Queue, SimpleQueue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5461e8d-aa44-45a6-a1e8-e8aa2d82f4d0",
   "metadata": {
    "id": "e5461e8d-aa44-45a6-a1e8-e8aa2d82f4d0",
    "tags": []
   },
   "source": [
    "## Settings and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b81a4-1880-4274-aeac-b6dc5926cf69",
   "metadata": {
    "id": "559b81a4-1880-4274-aeac-b6dc5926cf69"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3629976e-60c8-49d4-8788-c01e962bee53",
   "metadata": {
    "id": "3629976e-60c8-49d4-8788-c01e962bee53"
   },
   "outputs": [],
   "source": [
    "#data\n",
    "number_of_data     = 100\n",
    "observations_mean  = np.array([10. , 20.])\n",
    "observations_sd    = np.sqrt(5.)\n",
    "dimensionality = 2\n",
    "\n",
    "#prior\n",
    "prior_mean = np.array([12., 18.])\n",
    "prior_sd = np.sqrt(3.)\n",
    "\n",
    "#mcmc setting\n",
    "#x_start = np.array([14., 23.])\n",
    "#y_start = np.array([ 8., 16.])\n",
    "iterations = 1000\n",
    "burnin = 100\n",
    "\n",
    "# coupling tolerance\n",
    "chains_matching_tolerance = 1e-3\n",
    "\n",
    "# time averaged estimator parameter\n",
    "test_function_h = lambda x: x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9caa6f-e2c1-41a8-ab6d-a6fb9063f7c5",
   "metadata": {
    "id": "cb9caa6f-e2c1-41a8-ab6d-a6fb9063f7c5"
   },
   "source": [
    "### Funcion creations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e4cca-cf6c-4300-b06e-3715d4a987ce",
   "metadata": {
    "id": "1c5e4cca-cf6c-4300-b06e-3715d4a987ce"
   },
   "source": [
    "#### Generation of data\n",
    "Data are generated and placed in the variable \"observations_y\"; those data will be used in the likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f492a713-4975-48f0-b394-1f56ffb0d3fa",
   "metadata": {
    "id": "f492a713-4975-48f0-b394-1f56ffb0d3fa"
   },
   "outputs": [],
   "source": [
    "observations_y = np.array(\n",
    "    np.random.multivariate_normal(\n",
    "        mean=observations_mean, \n",
    "        cov=(observations_sd**2)*np.eye(dimensionality), \n",
    "        size=number_of_data\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95a2280-5a2b-4fef-8ee7-c40502384b7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b95a2280-5a2b-4fef-8ee7-c40502384b7d",
    "outputId": "0dfdb1e5-f79d-4bae-f534-9a9452ec210f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9da98c-df0a-47b0-82d0-c6d0b4bd1bb5",
   "metadata": {
    "id": "3c9da98c-df0a-47b0-82d0-c6d0b4bd1bb5"
   },
   "source": [
    "### Likelihood functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34013287-6570-49d6-a368-3a8b75c896a8",
   "metadata": {
    "id": "34013287-6570-49d6-a368-3a8b75c896a8"
   },
   "outputs": [],
   "source": [
    "def likelihood(mu):\n",
    "    tau = 1/(observations_sd**2)\n",
    "    return np.exp(  \n",
    "        -(tau/2)*( \n",
    "            number_of_data * (mu - observations_mean)**2 \n",
    "            + np.sum( (observations_y - observations_mean)**2, axis = 0) \n",
    "            )  \n",
    "        ) * 10.**10 #this coefficient is to avoid annihilation - it's a rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cfb38bd-29ce-4235-8845-835b3023b775",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cfb38bd-29ce-4235-8845-835b3023b775",
    "outputId": "22e746a8-bad5-4016-bd4a-52129c1028e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.51172676e-30, 2.08142411e-30])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood([12., 18.])#, observations_y, observations_mean, observations_sd, number_of_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b3386d-cb34-48e0-b1fa-af5a61451742",
   "metadata": {
    "id": "19b3386d-cb34-48e0-b1fa-af5a61451742"
   },
   "source": [
    "### Prior density function - setting of prior parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0723f995-f925-4173-9480-ba35269534bb",
   "metadata": {
    "id": "0723f995-f925-4173-9480-ba35269534bb"
   },
   "outputs": [],
   "source": [
    "def prior(value):\n",
    "    dimensionality =  prior_mean.shape[0]\n",
    "    return sstat.multivariate_normal(\n",
    "        prior_mean, \n",
    "        (prior_sd**2)*np.eye(dimensionality)\n",
    "        ).pdf(value)\n",
    "    #return tfd.MultivariateNormalTriL(\n",
    "    #    loc = prior_mean, \n",
    "    #    scale_tril = prior_sd*np.eye(dimensionality)\n",
    "    #    ).prob(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "976c7dad-f5cb-4397-9e46-99fc0a7640d9",
   "metadata": {
    "id": "976c7dad-f5cb-4397-9e46-99fc0a7640d9"
   },
   "outputs": [],
   "source": [
    "def prior_sampling():\n",
    "    dimensionality =  prior_mean.shape[0]\n",
    "    return sstat.multivariate_normal(\n",
    "        prior_mean, \n",
    "        (prior_sd**2)*np.eye(dimensionality)\n",
    "        ).rvs(1)\n",
    "    #return tfd.MultivariateNormalTriL(\n",
    "    #    loc = prior_mean, \n",
    "    #    scale_tril = prior_sd*np.eye(dimensionality)\n",
    "    #    ).sample(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe4508-7392-4142-a180-cfa7ac2eaa70",
   "metadata": {
    "id": "3cfe4508-7392-4142-a180-cfa7ac2eaa70"
   },
   "source": [
    "### Target distribution: posterior function\n",
    "posterior proportional to likelihood times prior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aea1bf8-3abb-4739-8b0c-562e0c4da7ca",
   "metadata": {
    "id": "8aea1bf8-3abb-4739-8b0c-562e0c4da7ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def target(value):\n",
    "    return likelihood(value)*prior(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ff4c5-d9f3-45e8-a4e2-021ce616f3aa",
   "metadata": {
    "id": "067ff4c5-d9f3-45e8-a4e2-021ce616f3aa"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9120084e-e867-4de4-a48f-6128814a89f8",
   "metadata": {
    "id": "9120084e-e867-4de4-a48f-6128814a89f8"
   },
   "source": [
    "### Maximal coupling of Q\n",
    "The algorithm:\n",
    "1)  \n",
    "    1) sample $X \\sim p$\n",
    "    2) sample $W|X \\sim \\mathcal{U}\\{[0,p(X)]\\}$ \\\n",
    "    if $W\\leq q(X)$ then output $(X,X)$\n",
    "2)  otherwise\n",
    "    1) sample $Y^\\star \\sim q$\n",
    "    2) sample $W^\\star | Y^\\star \\sim \\mathcal{U}\\{[0, q(Y^\\star)]\\}$ \\\n",
    "    until $W^\\star > p(Y^\\star)$ and output $(X,Y^\\star)$\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac35a816-97e2-4935-bfde-0a9fd313ec36",
   "metadata": {
    "id": "ac35a816-97e2-4935-bfde-0a9fd313ec36"
   },
   "outputs": [],
   "source": [
    "def maximal_coupling(x,y):     \n",
    "    #check dimensionality consistency\n",
    "    if len(x) != len(y):\n",
    "        raise NameError('Dimensionality mismatch!') \n",
    "    \n",
    "    dimensionality = len(x)\n",
    "\n",
    "    #sampling of X - point 1.A\n",
    "    #the new candidate is sampled from a normal centered in the given value\n",
    "    #x_candidate = np.random.multivariate_normal(mean=x, cov=np.eye(dimensionality), size=1)\n",
    "    x_candidate = sstat.multivariate_normal(x,np.eye(dimensionality)).rvs(1)\n",
    "    \n",
    "    #sampling of W|X - point 1.B\n",
    "    #evaluate pdf centered in x with scale 1 in x_cadidate\n",
    "    pX = sstat.multivariate_normal(x,np.eye(dimensionality)).pdf(x_candidate)\n",
    "    W = tfd.Uniform(0,pX).sample()\n",
    "    #sampling from uniform is inside the cycle on parameters \n",
    "    \n",
    "    # evaluation of qx - point 1 IF\n",
    "    qX = sstat.multivariate_normal(y, np.eye(dimensionality)).pdf(x_candidate)\n",
    "    \n",
    "    if W < qX:\n",
    "        x = x_candidate\n",
    "        y = x_candidate\n",
    "    else:\n",
    "        while True:\n",
    "            #sampling of Y* - point 2.A\n",
    "            y_candidate = sstat.multivariate_normal(y,np.eye(dimensionality)).rvs(1)\n",
    "\n",
    "            #sampling of W* - point 2.B\n",
    "            qY = sstat.multivariate_normal(y, np.eye(dimensionality)).pdf(y_candidate)\n",
    "            W =  tfd.Uniform(0,qY).sample()\n",
    "\n",
    "            # evaluation of py - point 2\n",
    "            pY = sstat.multivariate_normal(x,np.eye(dimensionality)).pdf(y_candidate)\n",
    "            if W > pY :\n",
    "                break\n",
    "\n",
    "        x = x_candidate\n",
    "        y = y_candidate\n",
    "\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031eaff-cea9-4b42-8116-5b02d3881222",
   "metadata": {
    "id": "3031eaff-cea9-4b42-8116-5b02d3881222"
   },
   "source": [
    "### Metropolis Hastings\n",
    "The algorithm:\n",
    "1) sample $(X^\\star, Y^\\star) | (X_t, Y_{t-1})$ from a maximal coupling of $q(X_t, \\cdot)$ and $q(Y_{t-1}, \\cdot)$\n",
    "2) sample $U \\sim \\mathcal{U}([0,1])$,\n",
    "3) if $$ U\n",
    " \t\t\t\t\\leq \\min\\bigg \\{\n",
    " \t\t\t\t1,\n",
    " \t\t\t\t\\frac{ \\pi(X^\\star)q(X^\\star,X_t)}{\n",
    " \t\t\t\t\t\\pi(X_t)q(X_t, X^\\star)}\n",
    " \t\t\t\t\\bigg \\} $$ then $X_{t+1} = X^\\star$; otherwise $X_t = X_{t-1}$;\n",
    "4) if $$ U\t\\leq \\min\\bigg \\{ \n",
    " \t\t\t\t1,\n",
    " \t\t\t\t\\frac{ \\pi(Y^\\star)q(Y^\\star,Y_t)}{\n",
    " \t\t\t\t\t\\pi(Y_t)q(Y_t, Y^\\star)}\n",
    " \t\t\t\t\\bigg \\} $$\n",
    "    then $Y_{t+1} = Y^\\star$; otherwise $Y_t = Y_{t-1}$.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15516f6d-0b98-46aa-835c-d560f57ccf9c",
   "metadata": {
    "id": "15516f6d-0b98-46aa-835c-d560f57ccf9c"
   },
   "outputs": [],
   "source": [
    "def metropolis_hastings(iterations):\n",
    "    \n",
    "    x = prior_sampling()\n",
    "    y = prior_sampling()\n",
    "    # check dimensionality consistency\n",
    "    if len(x) != len(y):\n",
    "        raise NameError('Dimensionality mismatch!') \n",
    "    \n",
    "    dimensionality = len(x)\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # initializing empty np arrays\n",
    "    X = np.empty([dimensionality, iterations])\n",
    "    Y = np.empty([dimensionality, iterations])\n",
    "\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # sample from maximal coupling - point 1\n",
    "        (x_candidate, y_candidate) = maximal_coupling(x,y) #da qui deve uscire già multivariato\n",
    "        x_candidate = np.array(x_candidate)\n",
    "        y_candidate = np.array(y_candidate)\n",
    "        \n",
    "        \n",
    "        # sample from a uniform - point 2\n",
    "        u = tfd.Uniform(0,1).sample()\n",
    "        \n",
    "        # points 3 and 4 are to be executed on all the parameters which determine the dimensionality\n",
    "        for param in range(dimensionality):\n",
    "            # check if the sampling of X is accepted or to consider the previous - point 3\n",
    "            if target(x)[param] == 0:              # to avoid zero division          \n",
    "                x[param] = x_candidate[param]        \n",
    "            elif u < min([1., target(x_candidate)[param]/target(x)[param]]) :\n",
    "                x[param] = x_candidate[param]       \n",
    "                        \n",
    "            X[param, i] = x[param]\n",
    "\n",
    "            # same for Y - point 4\n",
    "            if target(y)[param] == 0:                     \n",
    "                y[param] = y_candidate[param]      \n",
    "            elif u < min([1., target(y_candidate)[param]/target(y)[param]]) :\n",
    "                y[param] = y_candidate[param]        \n",
    "        \n",
    "            Y[param, i] = y[param]\n",
    "          \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0b530-77f3-4551-affa-79f2a7aba316",
   "metadata": {
    "id": "d6e0b530-77f3-4551-affa-79f2a7aba316",
    "tags": []
   },
   "source": [
    "### Time Averaged estimator\n",
    "The algorithm:\n",
    "1) draw $X_0$ and $Y_0$ from an initial distribution $\\pi_0$ and draw $X_1 \\sim P(X_0, \\cdot)$;\n",
    "2) set $t=1$: while $t<\\max\\{m,\\tau\\}$ and:\n",
    "    1) draw $(X_{t+1}, Y_t)\\sim \\bar P \\{(X_t, Y_{t-1}), \\cdot \\}$; \n",
    "    2) set $t \\leftarrow t+1$;\n",
    "3) compute the time-averaged estimator:\n",
    "\t$$ H_{k:m}(X,Y)\n",
    "\t \t\t= \\frac{1}{m-k+1}\\sum_{l=k}^{m}h(X_l) \n",
    "\t \t\t+ \\sum_{l=k+1}^{\\tau -1}\\min(1, \\frac{l-k}{m-k+1})\\{h(X_l)-h(Y_{l-1})\\} .\n",
    "\t \t\t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8396cbe-5186-4872-8b50-82b8afaf8488",
   "metadata": {
    "id": "f8396cbe-5186-4872-8b50-82b8afaf8488"
   },
   "outputs": [],
   "source": [
    "def time_averaged_estimator(red_chain, blue_chain, iterations, burnin, meeting_time):\n",
    "    #this function calculates only the formula at point 3\n",
    "    \n",
    "    #first addend\n",
    "    first_sum = 0\n",
    "    for i in range(burnin, iterations):\n",
    "        first_sum += test_function_h(red_chain[i])\n",
    "    \n",
    "    #second addend\n",
    "    second_sum = 0\n",
    "    if meeting_time-1 > burnin + 1:\n",
    "        for i in range(burnin + 1, meeting_time):\n",
    "            # calculing the coefficient, and the min\n",
    "            coef = (1-burnin)(iterations - burnin + 1)\n",
    "            if coef > 1:\n",
    "                coef = 1\n",
    "            second_sum += coef * (test_function_h(red_chain[i])- test_function_h(blue_chain[i]))\n",
    "            \n",
    "    return (1/(iterations - burnin + 1))*first_sum + second_sum\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d43b3-f427-4683-a6f1-35a1a8646791",
   "metadata": {
    "id": "733d43b3-f427-4683-a6f1-35a1a8646791"
   },
   "source": [
    "### Parallelized operations\n",
    "This function is given to each available processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "608973e4-9983-4894-a375-a7409cfb01f6",
   "metadata": {
    "id": "608973e4-9983-4894-a375-a7409cfb01f6"
   },
   "outputs": [],
   "source": [
    "def parallelized_operations(iterations, burnin, chains_matching_tolerance, q_chain, q_meeting_time, q_time_averaged_estimator):\n",
    "    # setting a random seed - otherwise multiprocessing has the same seed and so they end up in the same chains!\n",
    "    np.random.seed(int(os.getpid() * time.time()) % 123456789 )\n",
    "    tfr.set_seed(int(os.getpid() * time.time()) % 123456789 )\n",
    "    \n",
    "    #running metropolis hastings and obtaining two chains\n",
    "    (red_chain, blue_chain) = metropolis_hastings(iterations)\n",
    "    \n",
    "    #get the dimensionality from one of the chains\n",
    "    dimensionality = red_chain.shape[0]\n",
    "\n",
    "    #finding the meeting time\n",
    "    meeting_time = iterations + 2\n",
    "    for i in range(0, iterations-2):\n",
    "        if (abs(red_chain[:,i]-blue_chain[:,i]).all() < chains_matching_tolerance) & \\\n",
    "            (abs(red_chain[:,i+1]-blue_chain[:,i+1]).all() < chains_matching_tolerance) & \\\n",
    "            (abs(red_chain[:,i+2]-blue_chain[:,i+2]).all() < chains_matching_tolerance):\n",
    "            meeting_time = i\n",
    "            break\n",
    "    \n",
    "    #checking if the chains met\n",
    "    if meeting_time == iterations+2:\n",
    "        print('Matching did not occurred!')\n",
    "        print(meeting_time)\n",
    "        return\n",
    "    \n",
    "    #checking if the chains met before burnin\n",
    "    if meeting_time >= burnin:\n",
    "        print('Meeting time occurs after burnin iterations!')\n",
    "        print(meeting_time)\n",
    "        return\n",
    "    \n",
    "    time_averaged_estimation = np.empty(dimensionality)\n",
    "    \n",
    "    for param in range(dimensionality):\n",
    "        time_averaged_estimation[param] = time_averaged_estimator(\n",
    "            red_chain[param,], \n",
    "            blue_chain[param,], \n",
    "            iterations, burnin, meeting_time\n",
    "        )\n",
    "    #print(red_chain)\n",
    "    q_chain.put( red_chain )\n",
    "    q_meeting_time.put( meeting_time )\n",
    "    q_time_averaged_estimator.put( time_averaged_estimation )\n",
    "    \n",
    "    return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2fa33-4b3d-4673-80ee-7c7a697a3315",
   "metadata": {
    "id": "5ab2fa33-4b3d-4673-80ee-7c7a697a3315"
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cde0351-dc7f-44e7-87fc-71718cf2062e",
   "metadata": {
    "id": "9cde0351-dc7f-44e7-87fc-71718cf2062e"
   },
   "source": [
    "### Multiprocessing settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a243fa7a-3592-47e4-9d11-85c5f50a6544",
   "metadata": {
    "id": "3f86a375-80cc-4cf4-a85d-5b8d1e2d1995"
   },
   "outputs": [],
   "source": [
    "# this returns the number of available processors\n",
    "num_processes = os.cpu_count()\n",
    "num_processes\n",
    "\n",
    "# this set the number of iteration, it should be a multiple of the number of available processors\n",
    "num_batches_set = 8 #16*1 #set this\n",
    "num_batches = num_batches_set\n",
    "\n",
    "# this initialize a shared memory between processors\n",
    "# note of Queue(maxsize = 0)\n",
    "q_chain = SimpleQueue()\n",
    "q_meeting_time = SimpleQueue()\n",
    "q_time_averaged_estimator = SimpleQueue()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bef141c-6e1e-469a-b762-aae40d030673",
   "metadata": {
    "id": "1bef141c-6e1e-469a-b762-aae40d030673"
   },
   "source": [
    "### Multiprocessing execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33a4a10f-1c87-44f3-88a2-20ab3147cdde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33a4a10f-1c87-44f3-88a2-20ab3147cdde",
    "outputId": "70ba4e89-e628-4075-e919-f53a389a0bf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-3:\n",
      "Process Process-1:\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_23629/1845158363.py\", line 42, in parallelized_operations\n",
      "    q_chain.put( red_chain )\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_23629/1845158363.py\", line 42, in parallelized_operations\n",
      "    q_chain.put( red_chain )\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_23629/1845158363.py\", line 42, in parallelized_operations\n",
      "    q_chain.put( red_chain )\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 368, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 367, in put\n",
      "    with self._wlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 367, in put\n",
      "    with self._wlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_23629/1845158363.py\", line 42, in parallelized_operations\n",
      "    q_chain.put( red_chain )\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 367, in put\n",
      "    with self._wlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23629/4004389293.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# This assures that each process in the batch is complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#unfolding queues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dimensionality = observations_y.shape[1] #observations has inverted shape!\n",
    "\n",
    "samplings = np.empty([dimensionality, 0])#np.empty([dimensionality, 0])\n",
    "time_averaged_estimation_sum = 0\n",
    "meeting_times = np.empty(0)\n",
    "correct_chains = 0\n",
    "\n",
    "while num_batches > 0:\n",
    "    \n",
    "    print(\"There are \" + str(num_batches) + \" left\")\n",
    "    \n",
    "    if num_batches >= num_processes:\n",
    "        current_number_processes = num_processes\n",
    "    else:\n",
    "        current_number_processes = num_batches\n",
    "    \n",
    "    processes = []\n",
    "    for batch in range(current_number_processes):\n",
    "        p = Process(\n",
    "            target = parallelized_operations, \n",
    "            args = (iterations, burnin, \n",
    "                    chains_matching_tolerance, \n",
    "                    q_chain, q_meeting_time, q_time_averaged_estimator)\n",
    "        )\n",
    "        processes.append(p)\n",
    "\n",
    "    num_batches -= current_number_processes\n",
    "    \n",
    "    # Starting the processes in a batch\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # This assures that each process in the batch is complete\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    #unfolding queues\n",
    "    while not q_chain.empty():\n",
    "        red_chain = q_chain.get()\n",
    "        #print('lmao')\n",
    "        #print(red_chain)\n",
    "        samplings = np.append(\n",
    "            samplings,\n",
    "            red_chain[:,burnin :],\n",
    "            axis = 1\n",
    "        )\n",
    "\n",
    "        meeting_time = q_meeting_time.get()\n",
    "        time_averaged_estimation = q_time_averaged_estimator.get()\n",
    "        \n",
    "        if meeting_time <= burnin: #this to avoid a biased time averaged estimator\n",
    "            time_averaged_estimation_sum += time_averaged_estimation\n",
    "            correct_chains += 1\n",
    "        \n",
    "        meeting_times = np.append(\n",
    "            meeting_times,\n",
    "            meeting_time\n",
    "        )\n",
    "    \n",
    "del q_chain, q_meeting_time, q_time_averaged_estimator\n",
    "print('All processes are complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f637d1f-9d0f-43ad-9074-f49f894035b1",
   "metadata": {
    "id": "4f637d1f-9d0f-43ad-9074-f49f894035b1",
    "tags": []
   },
   "source": [
    "## Output and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff21ba5-4085-475c-a2e0-3624851591e4",
   "metadata": {},
   "source": [
    "### Correct executions infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e9eba-af9e-4179-b0ef-8a581b23ed24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "622e9eba-af9e-4179-b0ef-8a581b23ed24",
    "outputId": "ba951551-6841-4eac-e9f3-9641f388fe3e"
   },
   "outputs": [],
   "source": [
    "print(meeting_times)\n",
    "print(len(meeting_times))\n",
    "print(num_batches_set-len(meeting_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b35d720-f523-460d-92bd-57f06f1f9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplings.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d237883-533e-46fb-bc3f-4a2f26bf618e",
   "metadata": {},
   "source": [
    "### Time averaged estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e050d8-49f0-4c07-a0a2-28f408932437",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03e050d8-49f0-4c07-a0a2-28f408932437",
    "outputId": "f591dd0e-d445-4b5b-c10e-75b3b4273ca2"
   },
   "outputs": [],
   "source": [
    "time_averaged_estimation_mean = time_averaged_estimation_sum/correct_chains\n",
    "time_averaged_estimation_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080fa19-5f80-4b6e-8da0-360b33edd4f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e788bdc-9241-4155-9ea1-060a56a39ff0",
   "metadata": {
    "id": "hYIUQfdOdmwL"
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d292c73-29e7-42bb-b3e4-6d40eddfb451",
   "metadata": {},
   "source": [
    "#### Sampling plot and Histogram for all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0972b174-c9db-402b-affd-a96c9bdab751",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "0972b174-c9db-402b-affd-a96c9bdab751",
    "outputId": "4521201d-9cbc-49d4-dc7e-7fcead51f148"
   },
   "outputs": [],
   "source": [
    "for param in range(samplings.shape[0]):\n",
    "    plt.plot(samplings[param,:])\n",
    "plt.savefig('coupling_mult_sampling.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c9807-9717-440e-94f8-d68517828a97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "c35c9807-9717-440e-94f8-d68517828a97",
    "outputId": "0a7ed36e-4dc6-4104-8adb-83c060dfde4e"
   },
   "outputs": [],
   "source": [
    "for param in range(samplings.shape[0]):\n",
    "    plt.hist(samplings[param,:], bins = 10)\n",
    "plt.savefig('coupling_mult_histogram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cfcf0b-0a13-4f47-b7a3-6232681fb5ce",
   "metadata": {},
   "source": [
    "#### Sampling for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c124200-5209-47be-8025-6b24b094043a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "8c124200-5209-47be-8025-6b24b094043a",
    "outputId": "52aa45e8-a2fc-4e06-b260-7af31bbbba01"
   },
   "outputs": [],
   "source": [
    "plt.plot(samplings[0,:])\n",
    "plt.savefig('coupling_mult_sampling_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f242a5b-2d0a-4529-b802-0eb0217d2cb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "8c124200-5209-47be-8025-6b24b094043a",
    "outputId": "52aa45e8-a2fc-4e06-b260-7af31bbbba01"
   },
   "outputs": [],
   "source": [
    "plt.plot(samplings[1,:])\n",
    "plt.savefig('coupling_mult_sampling_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14982c-19ad-4ab5-aa95-45628cae9b0d",
   "metadata": {},
   "source": [
    "#### Meeting time for each variable\n",
    "Note that a MH is runned to have both chains as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e565470-57fe-4db0-aee1-c11b8941b230",
   "metadata": {
    "id": "2e565470-57fe-4db0-aee1-c11b8941b230"
   },
   "outputs": [],
   "source": [
    "(red_chain, blue_chain) = metropolis_hastings(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ca1d0-4f97-4bcc-91d9-8ac646e45168",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "a06ca1d0-4f97-4bcc-91d9-8ac646e45168",
    "outputId": "c3ded6e0-296d-4a3e-bb85-708c17c1400e"
   },
   "outputs": [],
   "source": [
    "plt.plot(red_chain[0,:])\n",
    "plt.plot(blue_chain[0,:])\n",
    "plt.savefig('coupling_mult_chain_meeeting_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52718554-e6a6-441c-bb8e-9eb396278bc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "a06ca1d0-4f97-4bcc-91d9-8ac646e45168",
    "outputId": "c3ded6e0-296d-4a3e-bb85-708c17c1400e"
   },
   "outputs": [],
   "source": [
    "plt.plot(red_chain[1,:])\n",
    "plt.plot(blue_chain[1,:])\n",
    "plt.savefig('coupling_mult_chain_meeeting_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95666149-7fcc-4489-9f94-41801e6a35a7",
   "metadata": {},
   "source": [
    "#### Histograms for all variables with real posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b96e8de-39c0-4e41-b28c-4ff09a0de69a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b96e8de-39c0-4e41-b28c-4ff09a0de69a",
    "outputId": "fcc3d002-7d39-47b2-bf30-a843633d21c0"
   },
   "outputs": [],
   "source": [
    "real_mu_1 = 1/(1/prior_sd**2 + number_of_data/observations_sd**2)*(prior_mean[0]/prior_sd**2 + (np.sum(observations_y[:,0])/observations_sd**2))\n",
    "real_mu_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bhZWMzKtMFQk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhZWMzKtMFQk",
    "outputId": "9e6d7e52-655b-47ed-fddd-bb8545fc2a62"
   },
   "outputs": [],
   "source": [
    "np.mean(samplings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baBm6lo3fU8S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "baBm6lo3fU8S",
    "outputId": "ed2b8d45-f067-4242-e749-3ee7f4a425e1"
   },
   "outputs": [],
   "source": [
    "real_mu_2 = 1/(1/prior_sd**2 + number_of_data/observations_sd**2)*(prior_mean[1]/prior_sd**2 + (np.sum(observations_y[:,1])/observations_sd**2))\n",
    "real_mu_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WwLS5MHEetvI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwLS5MHEetvI",
    "outputId": "58da249c-5fda-413e-ff0c-ef76a586c8c0"
   },
   "outputs": [],
   "source": [
    "np.mean(samplings[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a812c8-36b9-4ed9-918c-6631b2daf1fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2a812c8-36b9-4ed9-918c-6631b2daf1fc",
    "outputId": "63d3155a-eb32-4a5b-bef8-4355c45d4d97"
   },
   "outputs": [],
   "source": [
    "real_sd = np.sqrt(1/(1/prior_sd**2 + number_of_data/observations_sd**2))\n",
    "real_sd**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16TBhC4zI2ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16TBhC4zI2ad",
    "outputId": "14ab0ad1-4c72-4ce1-8b14-403390ae9139"
   },
   "outputs": [],
   "source": [
    "np.cov(samplings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf82fb3-c4e0-4f22-b5a2-6b147625fefc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "5cf82fb3-c4e0-4f22-b5a2-6b147625fefc",
    "outputId": "dcee4c12-d51d-4cac-b998-0ce042dcdfae"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(9.4, 10.8,100)\n",
    "\n",
    "plt.hist(samplings[0,:], bins = 30, density=True, label='Samples')\n",
    "plt.plot(x, sstat.norm.pdf(x, real_mu_1, real_sd ) , label= 'Posterior distribution' )\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('coupling_mult_histogram_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ey8sLkDtf_-z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "ey8sLkDtf_-z",
    "outputId": "5a458069-7aed-4ece-e5b3-453568fd4a33"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(19.3, 20.8, 100)\n",
    "\n",
    "plt.hist(samplings[1,:],bins = 30, density=True, label='Samples')\n",
    "plt.plot(x, sstat.norm.pdf(x, real_mu_2, real_sd ) , label= 'Posterior distribution' )\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('coupling_mult_histogram_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4f748-3054-43a3-b144-43da5c89300b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daebebff-f5e9-4e75-bf50-3ebda0a0aa50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5cd75-28d0-4ea6-9d67-fbe958e88c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985b464-52c1-4208-94d4-6996bb3b71d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6843c77-bf38-4ef9-8a8f-349552d494b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8122969-1324-4103-8daf-5bfbd10a92e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39df34-b1db-4812-a3b3-c9f3f6e2cb05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "mcmc_couplings_multivariate_CONPLOT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
